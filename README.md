# ğŸ›¡ï¸ Detetor de EPIs em Tempo Real

Este projeto Ã© um sistema de InteligÃªncia Artificial capaz de detetar o uso de Equipamentos de ProteÃ§Ã£o Individual (EPIs) em tempo real atravÃ©s de uma webcam. 

O modelo identifica mÃºltiplos equipamentos simultaneamente (ex.: uma pessoa pode estar a usar capacete e luvas ao mesmo tempo).

## Funcionalidades

- **DeteÃ§Ã£o em Tempo Real:** Processamento fotograma a fotograma via webcam
- **ClassificaÃ§Ã£o Multi-label:** Capaz de identificar vÃ¡rias classes na mesma imagem
- **Classes Treinadas:**
  - `capacete`
  - `luva`
  - `Ã³culos`
  - `sem_epi` (nenhum equipamento detetado)
- **VisualizaÃ§Ã£o:** Exibe a probabilidade de confianÃ§a (%) para cada item detetado no ecrÃ£

## Tecnologias Utilizadas

- **Linguagem:** Python 3
- **Deep Learning:** TensorFlow / Keras
- **Arquitetura:** MobileNetV2 (Transfer Learning)
- **VisÃ£o Computacional:** OpenCV
- **Processamento NumÃ©rico:** NumPy

## InstalaÃ§Ã£o e ConfiguraÃ§Ã£o

### 1. Clonar o repositÃ³rio

```bash
git clone https://github.com/seu-usuario/seu-repositorio.git
cd seu-repositorio
```

### 2. Configurar o Ambiente

Recomenda-se a criaÃ§Ã£o de um ambiente virtual para isolar as dependÃªncias:

```bash
# Windows
python -m venv venv
venv\Scripts\activate

# Linux/Mac
python3 -m venv venv
source venv/bin/activate
```

### 3. Instalar DependÃªncias

Com o ambiente ativo, instale todas as dependÃªncias necessÃ¡rias:

```bash
pip install -r requirements.txt
```

## Como Usar

### OpÃ§Ã£o A: Executar a DeteÃ§Ã£o (Webcam)

Para iniciar a deteÃ§Ã£o em tempo real usando o modelo jÃ¡ treinado:

```bash
python camera.py
```

- A webcam serÃ¡ aberta
- O sistema desenharÃ¡ caixas de texto com a percentagem de certeza
- Pressione a tecla **'q'** para encerrar o programa

### OpÃ§Ã£o B: Treinar um Novo Modelo

Caso queira treinar o modelo do zero com as suas prÃ³prias imagens:

**1. Organize o Dataset:** 

Crie uma pasta chamada `dataset` na raiz do projeto e organize as imagens em subpastas:

```
dataset/
â”œâ”€â”€ capacete/
â”œâ”€â”€ luva/
â”œâ”€â”€ Ã³culos/
â””â”€â”€ sem_epi/
```

**2. Inicie o Treino:**

```bash
python train.py
```

- O script farÃ¡ o *Fine-Tuning* na MobileNetV2
- O novo modelo serÃ¡ guardado como `models/meu_modelo_epi.h5`

## Estrutura do Projeto

```
.
â”œâ”€â”€ camera.py                    # Script principal de inferÃªncia (webcam)
â”œâ”€â”€ train.py                     # Script de treino da rede neuronal
â”œâ”€â”€ utils.py                     # FunÃ§Ãµes auxiliares
â”œâ”€â”€ requirements.txt             # DependÃªncias do projeto
â”œâ”€â”€ class_indices.json           # Mapeamento de classes (Label â†’ ID)
â”œâ”€â”€ models/
â”‚   â””â”€â”€ meu_modelo_epi.h5       # Modelo treinado
â””â”€â”€ dataset/                     # Pasta com imagens de treino
    â”œâ”€â”€ capacete/
    â”œâ”€â”€ luva/
    â”œâ”€â”€ Ã³culos/
    â””â”€â”€ sem_epi/
```

## Detalhes da Arquitetura

O projeto aplica **Transfer Learning** na rede **MobileNetV2**:

1. **Input:** Imagens redimensionadas para 224Ã—224 pÃ­xeis
2. **Feature Extraction:** Usa os pesos prÃ©-treinados da ImageNet (camadas congeladas)
3. **Classifier Head:**
   - `GlobalAveragePooling2D`
   - `Dropout (0.4)` (RegularizaÃ§Ã£o)
   - `Dense (Sigmoid)` (SaÃ­da)
4. **Loss Function:** `Binary Crossentropy` (ideal para classificaÃ§Ã£o multi-label)

## Requisitos do Sistema

- Python 3.7+
- Webcam funcional
- 4GB RAM (mÃ­nimo recomendado)
- GPU (opcional, mas recomendado para treino)

## ContribuiÃ§Ãµes

ContribuiÃ§Ãµes sÃ£o bem-vindas! Sinta-se Ã  vontade para:

1. Fazer um fork do projeto
2. Criar uma branch para sua feature (`git checkout -b feature/MinhaFeature`)
3. Commit suas mudanÃ§as (`git commit -m 'Adiciona MinhaFeature'`)
4. Push para a branch (`git push origin feature/MinhaFeature`)
5. Abrir um Pull Request

â­ Se este projeto foi Ãºtil para vocÃª, considere dar uma estrela no repositÃ³rio!
