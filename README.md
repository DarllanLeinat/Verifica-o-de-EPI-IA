````markdown
# ğŸ›¡ï¸ Detector de EPIs em Tempo Real (VisÃ£o Computacional)

Este projeto Ã© um sistema de InteligÃªncia Artificial capaz de detetar o uso de Equipamentos de ProteÃ§Ã£o Individual (EPIs) em tempo real atravÃ©s de uma webcam.

O modelo utiliza **Deep Learning** para identificar mÃºltiplos equipamentos simultaneamente (ex: uma pessoa pode estar a usar capacete e luvas ao mesmo tempo).

## ğŸ“‹ Funcionalidades

* **DeteÃ§Ã£o em Tempo Real:** Processamento frame a frame via webcam.
* **ClassificaÃ§Ã£o Multi-label:** Capaz de identificar vÃ¡rias classes na mesma imagem.
* **Classes Treinadas:**
    * `capacete`
    * `luva`
    * `Oculos`
    * `sem_epi` (nenhum equipamento detetado)
* **Feedback Visual:** Exibe a probabilidade de confianÃ§a (%) para cada item detetado no ecrÃ£.

## ğŸ› ï¸ Tecnologias Utilizadas

* **Linguagem:** Python 3.x
* **Framework:** TensorFlow / Keras
* **Modelo Base:** MobileNetV2 (Transfer Learning)
* **VisÃ£o Computacional:** OpenCV
* **DependÃªncias:** Geridas via `requirements.txt`

## ğŸš€ InstalaÃ§Ã£o e ConfiguraÃ§Ã£o

### 1. Clonar o repositÃ³rio
```bash
git clone [https://seu-repositorio-aqui.git](https://seu-repositorio-aqui.git)
cd nome-da-pasta
````

### 2\. Configurar o Ambiente

Recomenda-se a criaÃ§Ã£o de um ambiente virtual para isolar as dependÃªncias:

```bash
# Windows
python -m venv venv
venv\Scripts\activate

# Linux/Mac
python3 -m venv venv
source venv/bin/activate
```

### 3\. Instalar DependÃªncias

Com o ambiente ativo, instale tudo o que Ã© necessÃ¡rio automaticamente:

```bash
pip install -r requirements.txt
```

-----

## ğŸ’» Como Usar

### OpÃ§Ã£o A: Executar a DeteÃ§Ã£o (Webcam)

Para iniciar a deteÃ§Ã£o em tempo real usando o modelo jÃ¡ treinado:

```bash
python camera.py
```

  * A webcam serÃ¡ aberta.
  * O sistema desenharÃ¡ caixas de texto com a percentagem de certeza.
  * Pressione a tecla **'q'** para encerrar o programa.

### OpÃ§Ã£o B: Treinar um Novo Modelo

Caso queira treinar o modelo do zero com as suas prÃ³prias imagens:

1.  **Organize o Dataset:** Crie uma pasta chamada `dataset` na raiz do projeto e organize as imagens em subpastas:
    ```text
    /dataset
       â”œâ”€â”€ /capacete
       â”œâ”€â”€ /luva
       â”œâ”€â”€ /Oculos
       â””â”€â”€ /sem_epi
    ```
2.  **Inicie o Treino:**
    ```bash
    python train.py
    ```
      * O script farÃ¡ o *Fine-Tuning* na MobileNetV2.
      * O novo modelo serÃ¡ salvo como `models/meu_modelo_epi.h5`.

-----

## ğŸ“‚ Estrutura do Projeto

  * `camera.py`: Script principal de inferÃªncia (webcam).
  * `train.py`: Script de treino da rede neural (Transfer Learning).
  * `utils.py`: FunÃ§Ãµes auxiliares (processamento de imagem e I/O).
  * `requirements.txt`: Lista de dependÃªncias do projeto.
  * `class_indices.json`: Mapeamento de classes (Label -\> ID).
  * `models/meu_modelo_epi.h5`: O ficheiro binÃ¡rio da rede neural treinada.

## ğŸ§  Detalhes da Arquitetura

O projeto aplica **Transfer Learning** na rede **MobileNetV2**:

1.  **Input:** Imagens redimensionadas para 224x224 pixels.
2.  **Feature Extraction:** Usa os pesos prÃ©-treinados da ImageNet (camadas congeladas).
3.  **Classifier Head:**
      * `GlobalAveragePooling2D`
      * `Dropout (0.4)` (RegularizaÃ§Ã£o)
      * `Dense (Sigmoid)` (SaÃ­da)
4.  **Loss Function:** `Binary Crossentropy` (ideal para classificaÃ§Ã£o multi-label, onde as classes nÃ£o sÃ£o mutuamente exclusivas).

-----

## ğŸ”® Melhorias Futuras

  * [ ] Dockerizar a aplicaÃ§Ã£o para facilitar o deploy.
  * [ ] Criar uma API com Flask/FastAPI para receber imagens via HTTP.
  * [ ] Integrar com serviÃ§os de Cloud (Azure/GCP) para armazenamento de logs de deteÃ§Ã£o.

-----

## ğŸ“ Autor

Desenvolvido como projeto de VisÃ£o Computacional.

```
```
