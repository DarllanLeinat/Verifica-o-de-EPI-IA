# üõ°Ô∏è Detector de EPIs em Tempo Real

Este projeto √© um sistema de Intelig√™ncia Artificial capaz de detetar o uso de Equipamentos de Prote√ß√£o Individual (EPIs) em tempo real atrav√©s de uma webcam. 

O modelo identifica m√∫ltiplos equipamentos simultaneamente (ex: uma pessoa pode estar a usar capacete e luvas ao mesmo tempo).

## Funcionalidades

* **Dete√ß√£o em Tempo Real:** Processamento frame a frame via webcam.
* **Classifica√ß√£o Multi-label:** Capaz de identificar v√°rias classes na mesma imagem.
* **Classes Treinadas:**
    * `capacete`
    * `luva`
    * `Oculos`
    * `sem_epi` (nenhum equipamento detetado)
* **Visualiza√ß√£o:** Exibe a probabilidade de confian√ßa (%) para cada item detetado no ecr√£.

## Tecnologias Utilizadas

* **Linguagem:** Python 3
* **Deep Learning:** TensorFlow / Keras
* **Arquitetura:** MobileNetV2 (Transfer Learning)
* **Vis√£o Computacional:** OpenCV
* **Processamento Num√©rico:** NumPy

## üöÄ Instala√ß√£o e Configura√ß√£o

### 1. Clonar o reposit√≥rio
```bash
git clone [https://seu-repositorio-aqui.git](https://seu-repositorio-aqui.git)
cd nome-da-pasta

### 2\. Configurar o Ambiente

Recomenda-se a cria√ß√£o de um ambiente virtual para isolar as depend√™ncias:

```bash
# Windows
python -m venv venv
venv\Scripts\activate

# Linux/Mac
python3 -m venv venv
source venv/bin/activate
```

### 3\. Instalar Depend√™ncias

Com o ambiente ativo, instale tudo o que √© necess√°rio automaticamente:

```bash
pip install -r requirements.txt
```

-----

## Como Usar

### Op√ß√£o A: Executar a Dete√ß√£o (Webcam)

Para iniciar a dete√ß√£o em tempo real usando o modelo j√° treinado:

```bash
python camera.py
```

  * A webcam ser√° aberta.
  * O sistema desenhar√° caixas de texto com a percentagem de certeza.
  * Pressione a tecla **'q'** para encerrar o programa.

### Op√ß√£o B: Treinar um Novo Modelo

Caso queira treinar o modelo do zero com as suas pr√≥prias imagens:

1.  **Organize o Dataset:** Crie uma pasta chamada `dataset` na raiz do projeto e organize as imagens em subpastas:
    ```text
    /dataset
       ‚îú‚îÄ‚îÄ /capacete
       ‚îú‚îÄ‚îÄ /luva
       ‚îú‚îÄ‚îÄ /Oculos
       ‚îî‚îÄ‚îÄ /sem_epi
    ```
2.  **Inicie o Treino:**
    ```bash
    python train.py
    ```
      * O script far√° o *Fine-Tuning* na MobileNetV2.
      * O novo modelo ser√° salvo como `models/meu_modelo_epi.h5`.

-----

## Estrutura do Projeto

  * `camera.py`: Script principal de infer√™ncia (webcam).
  * `train.py`: Script de treino da rede neural (Transfer Learning).
  * `utils.py`: Fun√ß√µes auxiliares (processamento de imagem e I/O).
  * `requirements.txt`: Lista de depend√™ncias do projeto.
  * `class_indices.json`: Mapeamento de classes (Label -\> ID).
  * `models/meu_modelo_epi.h5`: O ficheiro bin√°rio da rede neural treinada.

## Detalhes da Arquitetura

O projeto aplica **Transfer Learning** na rede **MobileNetV2**:

1.  **Input:** Imagens redimensionadas para 224x224 pixels.
2.  **Feature Extraction:** Usa os pesos pr√©-treinados da ImageNet (camadas congeladas).
3.  **Classifier Head:**
      * `GlobalAveragePooling2D`
      * `Dropout (0.4)` (Regulariza√ß√£o)
      * `Dense (Sigmoid)` (Sa√≠da)
4.  **Loss Function:** `Binary Crossentropy` (ideal para classifica√ß√£o multi-label, onde as classes n√£o s√£o mutuamente exclusivas).

-----
